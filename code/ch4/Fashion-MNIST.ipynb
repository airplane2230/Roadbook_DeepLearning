{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fashion-MNIST 데이터셋 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets.fashion_mnist import load_data\n",
    "\n",
    "# Fashion-MNIST 데이터를 다운받습니다.\n",
    "(x_train, y_train), (x_test, y_test) = load_data()\n",
    "print(x_train.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 그려보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "np.random.seed(777)\n",
    "\n",
    "# Fashion-MNIST의 레이블에 해당하는 품목입니다.\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "sample_size = 9\n",
    "# 0 ~ 59999의 범위에서 무작위로 3개의 정수를 뽑습니다.\n",
    "random_idx = np.random.randint(60000, size=sample_size) \n",
    "\n",
    "plt.figure(figsize = (5, 5))\n",
    "for i, idx in enumerate(random_idx):\n",
    "    plt.subplot(3, 3, i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.imshow(x_train[idx], cmap = 'gray') # 20210218 오탈자\n",
    "    plt.xlabel(class_names[y_train[idx]]) # 20210218 오탈자\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 전처리 및 검증 데이터셋 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 값의 범위를 0 ~ 1로 만들어줍니다.\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# 각 데이터의 레이블을 범주형 형태로 변경합니다.\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "# 검증 데이터 세트를 만듭니다.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 훈련/테스트 데이터를 0.7/0.3의 비율로 분리합니다.\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, \n",
    "                                                  test_size = 0.3, random_state = 777)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 첫 번째 모델 구성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "\n",
    "first_model = Sequential()\n",
    "\n",
    "# 입력 데이터의 형태를 꼭 명시해야 합니다.\n",
    "first_model.add(Flatten(input_shape = (28, 28))) # (28, 28) -> .(28 * 28)\n",
    "first_model.add(Dense(64, activation = 'relu')) # 64개의 출력을 가지는 Dense 층\n",
    "first_model.add(Dense(32, activation = 'relu')) # 32개의 출력을 가지는 Dense 층\n",
    "first_model.add(Dense(10, activation = 'softmax')) # 10개의 출력을 가지는 신경망"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 과정 설정 및 학습하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_model.compile(optimizer='adam', # 옵티마이저 : Adam\n",
    "              loss = 'categorical_crossentropy', # 손실 함수 : categorical_crossentropy\n",
    "              metrics=['acc']) # 모니터링 할 평가지표 : acc\n",
    "\n",
    "first_history = first_model.fit(x_train, y_train, \n",
    "                    epochs = 30, \n",
    "                    batch_size = 128, \n",
    "                    validation_data = (x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 두 번째 모델 구성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "second_model = Sequential()\n",
    "\n",
    "# 입력 데이터의 형태를 꼭 명시해야 합니다.\n",
    "second_model.add(Flatten(input_shape = (28, 28))) # (28, 28) -> .(28 * 28)\n",
    "second_model.add(Dense(128, activation = 'relu')) # 128개의 출력을 가지는 Dense 층을 추가합니다.\n",
    "second_model.add(Dense(128, activation = 'relu')) # 64개의 출력을 가지는 Dense 층\n",
    "second_model.add(Dense(32, activation = 'relu')) # 32개의 출력을 가지는 Dense 층\n",
    "second_model.add(Dense(10, activation = 'softmax')) # 10개의 출력을 가지는 신경망\n",
    "\n",
    "second_model.compile(optimizer='adam', # 옵티마이저: Adam\n",
    "              loss = 'categorical_crossentropy', # 손실 함수: categorical_crossentropy\n",
    "              metrics=['acc']) # 모니터링 할 평가지표: acc(정확도)\n",
    "\n",
    "second_history = second_model.fit(x_train, y_train, \n",
    "                    epochs = 30, \n",
    "                    batch_size = 128, \n",
    "                    validation_data = (x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 두 모델의 학습 과정 그려보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def draw_loss_acc(history_1, history_2, epochs):\n",
    "    his_dict_1 = history_1.history\n",
    "    his_dict_2 = history_2.history\n",
    "    keys = list(his_dict_1.keys())\n",
    "    \n",
    "    epochs = range(1, epochs)\n",
    "    fig = plt.figure(figsize = (10, 10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    # axis 선과 ax의 축 레이블을 제거합니다.\n",
    "    ax.spines['top'].set_color('none')\n",
    "    ax.spines['bottom'].set_color('none')\n",
    "    ax.spines['left'].set_color('none')\n",
    "    ax.spines['right'].set_color('none')\n",
    "    ax.tick_params(labelcolor='w', top=False, bottom=False, left=False, right=False)\n",
    "    \n",
    "    for i in range(len(his_dict_1)):\n",
    "        temp_ax = fig.add_subplot(2, 2, i + 1)\n",
    "        temp = keys[i%2]\n",
    "        val_temp = keys[(i + 2)%2 + 2]\n",
    "        temp_history = his_dict_1 if i < 2 else his_dict_2\n",
    "        temp_ax.plot(epochs, temp_history[temp][1:], color = 'blue', label = 'train_' + temp)\n",
    "        temp_ax.plot(epochs, temp_history[val_temp][1:], color = 'orange', label = val_temp)\n",
    "        if(i == 1 or i == 3):\n",
    "            start, end = temp_ax.get_ylim()\n",
    "            temp_ax.yaxis.set_ticks(np.arange(np.round(start, 2), end, 0.01))\n",
    "        temp_ax.legend()\n",
    "    ax.set_ylabel('loss', size = 20)\n",
    "    ax.set_xlabel('Epochs', size = 20)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "draw_loss_acc(first_history, second_history, 30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jhw",
   "language": "python",
   "name": "jhw"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
