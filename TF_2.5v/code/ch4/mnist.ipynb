{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST 데이터셋 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets.mnist import load_data\n",
    "\n",
    "# 텐서플로우 저장소에서 데이터를 다운받습니다.\n",
    "(x_train, y_train), (x_test, y_test) = load_data(path='mnist.npz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터의 형태 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 훈련 데이터\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(y_train)\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "# 테스트 데이터\n",
    "print(x_test.shape, y_test.shape)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 그려보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "np.random.seed(777)\n",
    "\n",
    "sample_size = 3\n",
    "# 0~59999의 범위에서 무작위로 3개의 정수를 뽑습니다.\n",
    "random_idx = np.random.randint(60000, size = sample_size) \n",
    "\n",
    "for idx in random_idx:\n",
    "    img = x_train[idx, :]\n",
    "    label = y_train[idx]\n",
    "    plt.figure()\n",
    "    plt.imshow(img)\n",
    "    plt.title('%dth data, label is %d' % (idx,label), fontsize = 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 검증 데이터 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 훈련/테스트 데이터를 0.7/0.3의 비율로 분리합니다.\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, \n",
    "                                                  test_size = 0.3, \n",
    "                                                  random_state = 777)\n",
    "\n",
    "print(f'훈련 데이터:{x_train.shape}, 레이블:{y_train.shape}')\n",
    "print(f'검증 데이터:{x_val.shape}, 레이블:{y_val.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 입력을 위한 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_x_train = x_train.shape[0]\n",
    "num_x_val = x_val.shape[0]\n",
    "num_x_test = x_test.shape[0]\n",
    "\n",
    "# 모델의 입력으로 사용하기 위한 전처리 과정입니다.\n",
    "x_train = (x_train.reshape((num_x_train, 28 * 28))) / 255\n",
    "x_val = (x_val.reshape((num_x_val, 28 * 28))) / 255\n",
    "x_test = (x_test.reshape((num_x_test, 28 * 28))) / 255\n",
    "\n",
    "print(x_train.shape) # 모델 입력을 위해 데이터를 784차원으로 변경합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 입력을 위한 레이블 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# 각 데이터의 레이블을 범주형 형태로 변경합니다.\n",
    "y_train = to_categorical(y_train)\n",
    "y_val = to_categorical(y_val)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 구성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "# 입력 데이터의 형태를 꼭 명시해야 합니다.\n",
    "# 784차원의 데이터를 입력으로 받고, 64개의 출력을 가지는 첫 번째 Dense 층\n",
    "model.add(Dense(64, activation = 'relu', input_shape = (784, )))\n",
    "model.add(Dense(32, activation = 'relu')) # 32개의 출력을 가지는 Dense 층\n",
    "model.add(Dense(10, activation = 'softmax')) # 10개의 출력을 가지는 신경망"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 소프트맥스와 시그모이드 값의 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 소프트맥스 함수\n",
    "def softmax(arr):\n",
    "    m = np.max(arr)\n",
    "    arr = arr - m # exp의 오버플로우 방지\n",
    "    arr = np.exp(arr)\n",
    "    return arr / np.sum(arr)\n",
    "\n",
    "# 시그모이드 함수\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "case_1 = np.array([3.1, 3.0, 2.9])\n",
    "case_2 = np.array([2.0, 1.0, 0.7])\n",
    "\n",
    "np.set_printoptions(precision=3) # numpy 소수점 제한\n",
    "print(f'sigmoid {sigmoid(case_1)}, softmax {softmax(case_1)}')\n",
    "print(f'sigmoid {sigmoid(case_2)}, softmax {softmax(case_2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습과정 설정하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', # 옵티마이저 : Adam\n",
    "              loss = 'categorical_crossentropy', # 손실 함수 : categorical_crossentropy\n",
    "              metrics=['acc']) # 모니터링 할 평가지표 : acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 학습하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train, \n",
    "                    epochs = 30, \n",
    "                    batch_size = 128, \n",
    "                    validation_data = (x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## history를 통해 확인해볼 수 있는 값 출력하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 결과 그려보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "his_dict = history.history\n",
    "loss = his_dict['loss']\n",
    "val_loss = his_dict['val_loss'] # 검증 데이터가 있는 경우 ‘val_’ 수식어가 붙습니다.\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "fig = plt.figure(figsize = (10, 5))\n",
    "\n",
    "# 훈련 및 검증 손실 그리기\n",
    "ax1 = fig.add_subplot(1, 2, 1)\n",
    "ax1.plot(epochs, loss, color = 'blue', label = 'train_loss')\n",
    "ax1.plot(epochs, val_loss, color = 'orange', label = 'val_loss')\n",
    "ax1.set_title('train and val loss')\n",
    "ax1.set_xlabel('epochs')\n",
    "ax1.set_ylabel('loss')\n",
    "ax1.legend()\n",
    "\n",
    "acc = his_dict['acc']\n",
    "val_acc = his_dict['val_acc']\n",
    "\n",
    "# 훈련 및 검증 정확도 그리기\n",
    "ax2 = fig.add_subplot(1, 2, 2)\n",
    "ax2.plot(epochs, acc, color = 'blue', label = 'train_loss')\n",
    "ax2.plot(epochs, val_acc, color = 'orange', label = 'val_loss')\n",
    "ax2.set_title('train and val loss')\n",
    "ax2.set_xlabel('epochs')\n",
    "ax2.set_ylabel('loss')\n",
    "ax2.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습된 모델을 통해 값 예측하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(precision=7) # numpy 소수점 제한\n",
    "\n",
    "results = model.predict(x_test)\n",
    "\n",
    "print(results.shape)\n",
    "print(f'각 클래스에 속할 확률 : \\n{results[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예측값 그려서 확인해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "arg_results = np.argmax(results, axis = -1) # 가장 큰 값의 인덱스를 가져옵니다.\n",
    "plt.imshow(x_test[0].reshape(28, 28))\n",
    "plt.title('Predicted value of first image : ' + str(arg_results[0]), fontsize = 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 평가 방법 1 - 혼동 행렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn.metrics 모듈은 여러가지 평가 지표에 관한 기능을 제공합니다.\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 혼동 행렬을 만듭니다.\n",
    "plt.figure(figsize = (7, 7))\n",
    "cm = confusion_matrix(np.argmax(y_test, axis = -1), np.argmax(results, axis = -1))\n",
    "sns.heatmap(cm, annot = True, fmt = 'd',cmap = 'Blues')\n",
    "plt.xlabel('predicted label', fontsize = 15)\n",
    "plt.ylabel('true label', fontsize = 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 평가 방법 2 - 분류 보고서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n', classification_report(np.argmax(y_test, axis = -1), np.argmax(results, axis = -1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 전체 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets.mnist import load_data\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "tf.random.set_seed(777)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = load_data(path='mnist.npz')\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, \n",
    "                                                  test_size = 0.3, \n",
    "                                                  random_state = 777)\n",
    "\n",
    "num_x_train = x_train.shape[0]\n",
    "num_x_val = x_val.shape[0]\n",
    "num_x_test = x_test.shape[0]\n",
    "\n",
    "x_train = (x_train.reshape((num_x_train, 28 * 28))) / 255\n",
    "x_val = (x_val.reshape((num_x_val, 28 * 28))) / 255\n",
    "x_test = (x_test.reshape((num_x_test, 28 * 28))) / 255\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_val = to_categorical(y_val)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation = 'relu', input_shape = (784, )))\n",
    "model.add(Dense(32, activation = 'relu'))\n",
    "model.add(Dense(10, activation = 'softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss = 'categorical_crossentropy', \n",
    "              metrics=['acc'])\n",
    "\n",
    "history = model.fit(x_train, y_train, \n",
    "                    epochs = 30, \n",
    "                    batch_size = 128, \n",
    "                    validation_data = (x_val, y_val))\n",
    "\n",
    "# model.evaluate(x_test, y_test)\n",
    "results = model.predict(x_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jhw",
   "language": "python",
   "name": "jhw"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
